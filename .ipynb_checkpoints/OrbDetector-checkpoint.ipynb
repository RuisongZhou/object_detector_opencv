{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import pyramid_gaussian, integral_image\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, project_id=None):\n",
    "        if project_id:\n",
    "            self.project_id = project_id\n",
    "        else:\n",
    "            self.project_id = \"PROJECT_ORB_RGB\"\n",
    "        \n",
    "        ## 路径参数\n",
    "        self.set_path()\n",
    "        self.check_path()\n",
    "        \n",
    "        ## ORB特征参数\n",
    "        self.ORBParam = {\n",
    "            \"nfeatures\" : 200,   # 提取最多特征点的数量\n",
    "            \"scales\" : 1.2,      # 金字塔图像之间的尺寸参数\n",
    "            \"nlevels\" : 8,       # 高斯金字塔的层数\n",
    "            \"edgethresh\" : 2,   # 主要根据patchsize来决定检测多少邻域\n",
    "            \"wetk\" : 2,          # 产生BIREF描述子的点对个数，默认一般为2个\n",
    "            #\"scoretype\" : cv2.ORB_HARRIS_SCORE,\n",
    "            \"patchsize\" : 10     # 用于计算BIREF描述子特征点邻域大小\n",
    "        }\n",
    "        \n",
    "        ## K-means聚类参数\n",
    "        self.minibatch = True      # 是否使用minibatchkmeans\n",
    "        self.Kmeans = {\n",
    "            \"n\" : 128,               # 聚类簇数\n",
    "            \"init\" : 'k-means++',   # 初始值选择算法\n",
    "            \"n_init\" : 10,          # 重新选择初始值的次数\n",
    "            \"max_iter\" : 300,       # 单次初始值计算的最大迭代次数 \n",
    "            \"tol\" : 0.0001,         # 容忍度，kmeans运行准则收敛条件\n",
    "            \"n_jobs\" : 1,           # 并行数\n",
    "            \"algorithm\":'auto',     # k-means实现算法\n",
    "            \"batch_size\":10000        # MiniBatchKmeans的batchsize\n",
    "        }\n",
    "        \n",
    "        \n",
    "        ## 颜色直方图特征参数\n",
    "        self.RGBParam = {\n",
    "            \"channels\" : 3,\n",
    "            \"dims\" : 3\n",
    "        }\n",
    "        \n",
    "    def set_path(self):\n",
    "        ## 设置路径参数\n",
    "        self.DirPath = {\n",
    "            \"POS_DIR_PATH\" : \"./source/images/pos\",      # 正样本路径\n",
    "            \"NEG_DIR_PATH\" : \"./source/images/neg_new\",  # 负样本路径\n",
    "            \"TEST_DIR_PATH\" : \"./source/test_images\",    # 测试样本路径\n",
    "            \"FEAT_EXTRACTOR_PATH\" : os.path.join(\"./source/extractor\", self.project_id), # 保存图像的特征extractor\n",
    "            \"MODEL_DIR_PATH\" : os.path.join(\"./source/models\", self.project_id), # 保存模型的路径\n",
    "            \"FEAT_DIR_PATH\" : os.path.join(\"./source/features\", self.project_id), # 保存将样本转化为features的文件路径\n",
    "            \"PRED_SAVE_PATH\" : os.path.join(\"./source/predictions\", self.project_id) # 保存预测结果路径\n",
    "        }\n",
    "    def check_path(self):\n",
    "        ## 检查路径是否存在\n",
    "        for path in self.DirPath.values():\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "                print(\"成功新建文件夹: \", path)\n",
    "##############\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用ORB特征点思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Step1：使用ORB特征点检测函数检测特征点并生成特征点的描述子。\n",
    "+ Step2：使用K-means对特征点向量进行聚类。\n",
    "+ Step3：使用聚类和SVM训练特征点到图像的分类关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用颜色直方图思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Step1：统计颜色直方图，按照某一分度将颜色划分成等长的区域。\n",
    "+ Step2：统计直方图生成颜色直方图向量，并归一化。\n",
    "+ Step3：对直方图向量使用SVM进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现ORB特征生成和聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化ORB\n"
     ]
    }
   ],
   "source": [
    "class ORBExtractor():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        ## 初始化ORB特征点生成器\n",
    "        print(\"初始化ORB\")\n",
    "        self.orb = cv2.ORB_create(nfeatures=config.ORBParam[\"nfeatures\"],\n",
    "                             scaleFactor=config.ORBParam[\"scales\"],\n",
    "                             nlevels=config.ORBParam[\"nlevels\"],\n",
    "                             edgeThreshold=config.ORBParam[\"edgethresh\"],\n",
    "                             WTA_K=config.ORBParam[\"wetk\"],\n",
    "                             scoreType=cv2.ORB_HARRIS_SCORE,\n",
    "                             patchSize=config.ORBParam[\"patchsize\"])\n",
    "        \n",
    "    def ExtractORB(self, image):\n",
    "        '''\n",
    "        func : 输入一张图片，返回该图片的特征点的向量.\n",
    "        param :\n",
    "            image : 输入图片\n",
    "        return : 二维数组，shape(kp_num, feature_dim)\n",
    "        '''\n",
    "        kp, des = self.orb.detectAndCompute(image, None)\n",
    "        return kp, des\n",
    "    \n",
    "    def DrawKeyPoints(self, keypoints, image):\n",
    "        '''\n",
    "        func : 将特征点画在图像上并显示\n",
    "        param : \n",
    "            image : 输入图像\n",
    "            keypoints : 通过ORB提取的特征点\n",
    "        return :\n",
    "            None\n",
    "        '''\n",
    "        img = cv2.drawKeypoints(image, keypoints, None, (0,0,255), 0)\n",
    "        plt.imshow(img)\n",
    "####################\n",
    "extractor = ORBExtractor(config)\n",
    "## 保存ORBExtractor\n",
    "#joblib.dump(extractor, os.path.join(config.DirPath[\"FEAT_EXTRACTOR_PATH\"], config.project_id+\"_feat_extractor.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9731 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正样本图像关键点提取......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [00:12<00:00, 755.43it/s] \n",
      "  0%|          | 5/6432 [00:00<02:35, 41.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "负样本图像关键点提取......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6432/6432 [00:26<00:00, 245.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并特征点向量\n",
      "使用MinibatchKmeans聚类......\n",
      "==> 耗费时间 : 12.249191522598267s\n"
     ]
    }
   ],
   "source": [
    "## 从图片中Extract出特征点向量\n",
    "PosImageDir = config.DirPath[\"POS_DIR_PATH\"]\n",
    "NegImageDir = config.DirPath[\"NEG_DIR_PATH\"]\n",
    "KeyPointList = []  # 用于保有存所的关键点\n",
    "\n",
    "## 循环遍历图片路径并extract出关键点\n",
    "print(\"正样本图像关键点提取......\")\n",
    "for path in tqdm.tqdm(os.listdir(PosImageDir)):\n",
    "    image = cv2.imread(os.path.join(PosImageDir, path), 0)\n",
    "    KeyPointList.append(extractor.ExtractORB(image)[1])\n",
    "print(\"负样本图像关键点提取......\")\n",
    "for path in tqdm.tqdm(os.listdir(NegImageDir)):\n",
    "    image = cv2.imread(os.path.join(NegImageDir, path), 0)\n",
    "    KeyPointList.append(extractor.ExtractORB(image)[1])\n",
    "\n",
    "## 合并这些特征点向量\n",
    "print(\"合并特征点向量\")\n",
    "def notNone(x):\n",
    "    if type(x) == type(None):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "KeyPointList = list(filter(notNone, KeyPointList)) # 过滤掉None\n",
    "PointFeatures = np.concatenate(tuple(KeyPointList), axis=0)\n",
    "np.random.shuffle(PointFeatures) # 对点的特征向量进行聚类\n",
    "PointFeaturesNorm = 1.0*(PointFeatures - PointFeatures.mean()) / PointFeatures.std()  # 对数据标准化\n",
    "\n",
    "## 对这些特征向量进行聚类\n",
    "start_time = time.time()\n",
    "if not config.minibatch:\n",
    "    print(\"使用K-means进行聚类......\")\n",
    "    km = KMeans(n_clusters=config.Kmeans[\"n\"],\n",
    "                       init=config.Kmeans[\"init\"],\n",
    "                       n_init=config.Kmeans[\"n_init\"],\n",
    "                       max_iter=config.Kmeans[\"max_iter\"],\n",
    "                       tol=config.Kmeans[\"tol\"],\n",
    "                       n_jobs=config.Kmeans[\"n_jobs\"],\n",
    "                       algorithm=config.Kmeans[\"algorithm\"])\n",
    "    km.fit(PointFeaturesNorm) # 聚类\n",
    "else:\n",
    "    print(\"使用MinibatchKmeans聚类......\")\n",
    "    km = MiniBatchKMeans(n_clusters=config.Kmeans[\"n\"],\n",
    "                       init=config.Kmeans[\"init\"],\n",
    "                       n_init=config.Kmeans[\"n_init\"],\n",
    "                       max_iter=config.Kmeans[\"max_iter\"],\n",
    "                       batch_size=config.Kmeans[\"batch_size\"],\n",
    "                       tol=config.Kmeans[\"tol\"])\n",
    "    km.fit(PointFeaturesNorm)\n",
    "end_time = time.time()\n",
    "print(\"==> 耗费时间 : {}s\".format(end_time-start_time))\n",
    "\n",
    "## 保存k-means的模型\n",
    "#print(\"保存K-means模型......\")\n",
    "#joblib.dump(km, os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_kmeans.pkl\"))\n",
    "#param = {\"mean\" : PointFeatures.mean(), \"std\" : PointFeatures.std()}\n",
    "#joblib.dump(param, os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_kmeans_param.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用聚类器预测特征点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load k-means......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/9731 [00:00<00:59, 162.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正样本图像关键点提取......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9731/9731 [00:17<00:00, 540.81it/s]\n",
      "100%|██████████| 1553/1553 [00:03<00:00, 428.23it/s]\n",
      "  1%|▏         | 87/6432 [00:00<00:07, 865.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "负样本图像关键点提取......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6432/6432 [00:07<00:00, 898.87it/s] \n",
      "100%|██████████| 2000/2000 [00:06<00:00, 320.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./source/features/PROJECT_ORB_RGB/PROJECT_ORB_RGB_neg_features.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 读取K-means聚类器\n",
    "print(\"Load k-means......\")\n",
    "## 载入参数\n",
    "km = joblib.load(os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_kmeans.pkl\"))\n",
    "param = joblib.load(os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_kmeans_param.pkl\"))\n",
    "mean = param[\"mean\"]\n",
    "std = param[\"std\"]\n",
    "## 读取训练数据\n",
    "PosImageDirs = [config.DirPath[\"POS_DIR_PATH\"], \"./source/images/no_hands/pos/\"]\n",
    "NegImageDirs = [config.DirPath[\"NEG_DIR_PATH\"], \"./source/images/neg/\"]\n",
    "PosSamples = []  # 用于保存正样本\n",
    "NegSamples = []  # 用于保存负样本\n",
    "\n",
    "def GetPosNegSamples(PosImageDirs, NegImageDirs):\n",
    "    '''\n",
    "    func : 遍历样本图片生成ORB特征\n",
    "    param : \n",
    "        PosImageDirs : 正样本图片文件夹路径列表\n",
    "        NegImageDirs : 负样本图片文件夹路径列表\n",
    "    return :\n",
    "        None\n",
    "    '''\n",
    "    print(\"正样本图像关键点提取......\")\n",
    "    for dir_name in PosImageDirs:\n",
    "        for path in tqdm.tqdm(os.listdir(dir_name)):\n",
    "            image = cv2.imread(os.path.join(dir_name, path), 0)\n",
    "            feat = extractor.ExtractORB(image)[1] # 得到图片的ORB特征点\n",
    "            if type(feat) == type(None): # 如果没有找到特征点\n",
    "                PosSamples.append(np.array([]))\n",
    "                continue\n",
    "            feat = 1.0*(feat-mean)/std\n",
    "            feat = km.predict(feat) # 使用km对特征点进行归类\n",
    "            PosSamples.append(feat)\n",
    "    print(\"负样本图像关键点提取......\")\n",
    "    for dir_name in NegImageDirs:\n",
    "        for path in tqdm.tqdm(os.listdir(dir_name)):\n",
    "            image = cv2.imread(os.path.join(dir_name, path), 0)\n",
    "            feat = extractor.ExtractORB(image)[1] # 得到图片的ORB特征点\n",
    "            if type(feat) == type(None): # 如果没有找到特征点\n",
    "                NegSamples.append(np.array([]))\n",
    "                continue\n",
    "            feat = 1.0*(feat-mean)/std\n",
    "            feat = km.predict(feat) # 使用km对特征点进行归类\n",
    "            NegSamples.append(feat)\n",
    "\n",
    "GetPosNegSamples(PosImageDirs, NegImageDirs)\n",
    "## 保存生成的特征\n",
    "joblib.dump(PosSamples, os.path.join(config.DirPath[\"FEAT_DIR_PATH\"], config.project_id+\"_pos_features.pkl\"))\n",
    "joblib.dump(NegSamples, os.path.join(config.DirPath[\"FEAT_DIR_PATH\"], config.project_id+\"_neg_features.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将feature转化为统计向量和SVM训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 用于将一个特征类别向量转化为统计向量\n",
    "n_range = config.Kmeans[\"n\"]\n",
    "def GenOneHot(arr):\n",
    "    oh = np.zeros((n_range,))\n",
    "    for i in arr:\n",
    "        oh[i] += 1\n",
    "    return oh\n",
    "## 载入features\n",
    "print(\"载入features......\")\n",
    "PosSamples = joblib.load(os.path.join(config.DirPath[\"FEAT_DIR_PATH\"], config.project_id+\"_pos_features.pkl\"))\n",
    "NegSamples = joblib.load(os.path.join(config.DirPath[\"FEAT_DIR_PATH\"], config.project_id+\"_neg_features.pkl\"))\n",
    "## 将向量转化为统计向量\n",
    "PosSamples = list(map(GenOneHot, PosSamples))\n",
    "NegSamples = list(map(GenOneHot, NegSamples))\n",
    "X = np.concatenate([PosSamples, NegSamples], axis=0) # 连接正负样本\n",
    "Y = np.concatenate([np.array([1]*len(PosSamples)), np.array([0]*len(NegSamples))])\n",
    "print(\"总共的样本个数：{}，正样本个数：{}，负样本个数：{}\".format(len(X), len(PosSamples), len(NegSamples)))\n",
    "\n",
    "## shuffle and train\n",
    "print(\"训练SVM......\")\n",
    "X, Y = shuffle(X, Y, random_state=0)\n",
    "clf = svm.SVC(C=1.0,\n",
    "              kernel=\"linear\",\n",
    "              probability=True)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "## 将SVM模型保存\n",
    "#print(\"保存SVM模型......\")\n",
    "#joblib.dump(clf, os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_svm.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存SVM模型......\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./source/models/PROJECT_ORB_RGB/PROJECT_ORB_RGB_svm.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 将SVM模型保存\n",
    "print(\"保存SVM模型......\")\n",
    "joblib.dump(clf, os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_svm.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建分类函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 用于将一个特征类别向量转化为统计向量\n",
    "n_range = config.Kmeans[\"n\"]\n",
    "def GenOneHot(arr):\n",
    "    oh = np.zeros((n_range,))\n",
    "    for i in arr:\n",
    "        oh[i] += 1\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load K-means......\n"
     ]
    }
   ],
   "source": [
    "## 得到extractor，image->features\n",
    "# extractor\n",
    "## 得到k-means分类器，features->clusters\n",
    "print(\"Load K-means......\")\n",
    "km = joblib.load(os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_kmeans.pkl\"))\n",
    "param = joblib.load(os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_kmeans_param.pkl\"))\n",
    "mean = param[\"mean\"]\n",
    "std = param[\"std\"]\n",
    "## 得到svm二分类器，clusters->statistics vector->result\n",
    "#print(\"Load SVM......\")\n",
    "clf = joblib.load(os.path.join(config.DirPath[\"MODEL_DIR_PATH\"], config.project_id+\"_svm.pkl\"))\n",
    "\n",
    "n_range = config.Kmeans[\"n\"]\n",
    "def Classifier(image, score=False):\n",
    "    '''\n",
    "    func : 用于对输入的图片进行分类是否含有卡片\n",
    "    param :\n",
    "        image : 输入图像\n",
    "    return :\n",
    "        False : 无卡片\n",
    "        True : 有卡片\n",
    "    '''\n",
    "    feat = extractor.ExtractORB(image)[1] # 从图像提取点特征\n",
    "    if type(feat) == type(None):  # 如果提取不出特征\n",
    "        feat = np.array([0]*config.Kmeans[\"n\"])\n",
    "    else:\n",
    "        feat = 1.0*(feat-mean)/std # 归一化\n",
    "        feat = km.predict(feat) # 把特征点进行归类到簇\n",
    "        feat = GenOneHot(feat) # 将特征点向量转化成统计向量\n",
    "    if not score:\n",
    "#         pred = clf.predict([feat]) # 使用SVM进行预测\n",
    "        score = clf.decision_function([feat])[0]\n",
    "        if score > 1.5:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return clf.decision_function([feat])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0bd5180d65b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./source/images/neg/2.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-e66d3cff3bee>\u001b[0m in \u001b[0;36mClassifier\u001b[0;34m(image, score)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mTrue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m有卡片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     '''\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtractORB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 从图像提取点特征\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 如果提取不出特征\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extractor' is not defined"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "img = cv2.imread(\"./source/images/neg/2.jpg\", 0)\n",
    "Classifier(img, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行滑动窗口分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_area(detection_1, detection_2):\n",
    "    \"\"\"\n",
    "        Function to calculate overlapping area'si\n",
    "        `detection_1` and `detection_2` are 2 detections whose area\n",
    "        of overlap needs to be found out.\n",
    "        Each detection is list in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        The function returns a value between 0 and 1,\n",
    "        which represents the area of overlap.\n",
    "        0 is no overlap and 1 is complete overlap.\n",
    "        Area calculated from ->\n",
    "        http://math.stackexchange.com/questions/99565/simplest-way-to-calculate-the-intersect-area-of-two-rectangles\n",
    "    \"\"\"\n",
    "    # Calculate the x-y co-ordinates of the rectangles\n",
    "    x1_tl = detection_1[0]\n",
    "    x2_tl = detection_2[0]\n",
    "    x1_br = detection_1[0] + detection_1[3]\n",
    "    x2_br = detection_2[0] + detection_2[3]\n",
    "    y1_tl = detection_1[1]\n",
    "    y2_tl = detection_2[1]\n",
    "    y1_br = detection_1[1] + detection_1[4]\n",
    "    y2_br = detection_2[1] + detection_2[4]\n",
    "    # Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br) - max(x1_tl, x2_tl))\n",
    "    y_overlap = max(0, min(y1_br, y2_br) - max(y1_tl, y2_tl))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = detection_1[3] * detection_2[4]\n",
    "    area_2 = detection_2[3] * detection_2[4]\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    return overlap_area / float(total_area)\n",
    "\n",
    "def nms(detections, threshold=.5):\n",
    "    \"\"\"\n",
    "        This function performs Non-Maxima Suppression.\n",
    "        `detections` consists of a list of detections.\n",
    "        Each detection is in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        If the area of overlap is greater than the `threshold`,\n",
    "        the area with the lower confidence score is removed.\n",
    "        The output is a list of detections.\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    # Sort the detections based on confidence score\n",
    "    detections = sorted(detections, key=lambda detections: detections[2],\n",
    "                        reverse=True)\n",
    "    new_detections = [] # Unique detections will be appended to this list\n",
    "    new_detections.append(detections[0]) # Append the first detection\n",
    "    del detections[0] # Remove the detection from the original list\n",
    "    \"\"\"\n",
    "        For each detection, calculate the overlapping area\n",
    "        and if area of overlap is less than the threshold set\n",
    "        for the detections in `new_detections`, append the \n",
    "        detection to `new_detections`.\n",
    "        In either case, remove the detection from `detections` list.\n",
    "    \"\"\"\n",
    "    for index, detection in enumerate(detections):\n",
    "        for new_detection in new_detections:\n",
    "            if overlapping_area(detection, new_detection) > threshold:\n",
    "                del detections[index]\n",
    "                break\n",
    "        else:\n",
    "            new_detections.append(detection)\n",
    "            del detections[index]\n",
    "    return new_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2320, 2320)\n",
      "Processing image ./source/test_images/test_9.JPG, shape (256, 256)\n",
      "==> Location -> (60, 72)\n",
      "==> Scale -> 0 Confidence Score 2.1312403301142293 \n",
      "==> Location -> (72, 72)\n",
      "==> Scale -> 0 Confidence Score 1.545871986645812 \n",
      "==> Location -> (96, 72)\n",
      "==> Scale -> 0 Confidence Score 2.753934784141398 \n",
      "==> Location -> (108, 72)\n",
      "==> Scale -> 0 Confidence Score 2.411431295348171 \n",
      "==> Location -> (120, 72)\n",
      "==> Scale -> 0 Confidence Score 2.587697810239211 \n",
      "==> Location -> (132, 72)\n",
      "==> Scale -> 0 Confidence Score 4.351154874039144 \n",
      "==> Location -> (144, 72)\n",
      "==> Scale -> 0 Confidence Score 2.371092241371576 \n",
      "==> Location -> (48, 84)\n",
      "==> Scale -> 0 Confidence Score 2.4131554671892044 \n",
      "==> Location -> (60, 84)\n",
      "==> Scale -> 0 Confidence Score 2.4296722966280466 \n",
      "==> Location -> (96, 84)\n",
      "==> Scale -> 0 Confidence Score 2.132491435542539 \n",
      "==> Location -> (108, 84)\n",
      "==> Scale -> 0 Confidence Score 2.8553645073348033 \n",
      "==> Location -> (120, 84)\n",
      "==> Scale -> 0 Confidence Score 2.7916239958160585 \n",
      "==> Location -> (132, 84)\n",
      "==> Scale -> 0 Confidence Score 3.8918834456769726 \n",
      "==> Location -> (144, 84)\n",
      "==> Scale -> 0 Confidence Score 1.8134186175320843 \n",
      "==> Location -> (84, 96)\n",
      "==> Scale -> 0 Confidence Score 1.5135901943483583 \n",
      "==> Location -> (96, 96)\n",
      "==> Scale -> 0 Confidence Score 2.2992609286773185 \n",
      "==> Location -> (120, 96)\n",
      "==> Scale -> 0 Confidence Score 2.442310906546032 \n",
      "==> Location -> (132, 96)\n",
      "==> Scale -> 0 Confidence Score 2.5972272404842496 \n",
      "==> Location -> (60, 108)\n",
      "==> Scale -> 0 Confidence Score 1.504591713061023 \n",
      "==> Location -> (96, 108)\n",
      "==> Scale -> 0 Confidence Score 1.6855809874562107 \n",
      "==> Location -> (108, 108)\n",
      "==> Scale -> 0 Confidence Score 2.2711112181282314 \n",
      "==> Location -> (132, 108)\n",
      "==> Scale -> 0 Confidence Score 1.8028200075222054 \n",
      "==> Location -> (144, 108)\n",
      "==> Scale -> 0 Confidence Score 1.7159856631067265 \n",
      "==> Location -> (0, 132)\n",
      "==> Scale -> 0 Confidence Score 1.8470185444016403 \n",
      "==> Location -> (168, 144)\n",
      "==> Scale -> 0 Confidence Score 1.9323777527774888 \n",
      "==> Location -> (180, 144)\n",
      "==> Scale -> 0 Confidence Score 1.6818520402350765 \n",
      "==> Location -> (168, 156)\n",
      "==> Scale -> 0 Confidence Score 2.228779246097252 \n",
      "==> Location -> (180, 156)\n",
      "==> Scale -> 0 Confidence Score 2.8775669476974652 \n",
      "==> Location -> (180, 168)\n",
      "==> Scale -> 0 Confidence Score 2.172240746905805 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruisongzhou/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Location -> (72, 48)\n",
      "==> Scale -> 1 Confidence Score 1.7049845217959552 \n",
      "==> Location -> (84, 48)\n",
      "==> Scale -> 1 Confidence Score 2.6706940044480287 \n",
      "==> Location -> (96, 48)\n",
      "==> Scale -> 1 Confidence Score 2.071565481362091 \n",
      "==> Location -> (108, 48)\n",
      "==> Scale -> 1 Confidence Score 1.8906717819202237 \n",
      "==> Location -> (60, 60)\n",
      "==> Scale -> 1 Confidence Score 1.5598221356433493 \n",
      "==> Location -> (84, 60)\n",
      "==> Scale -> 1 Confidence Score 3.2898403701622154 \n",
      "==> Location -> (108, 60)\n",
      "==> Scale -> 1 Confidence Score 1.6012882223667526 \n",
      "==> Location -> (48, 72)\n",
      "==> Scale -> 1 Confidence Score 1.9341291630253232 \n",
      "==> Location -> (60, 72)\n",
      "==> Scale -> 1 Confidence Score 1.6141421705053796 \n",
      "==> Location -> (72, 72)\n",
      "==> Scale -> 1 Confidence Score 2.2881170718856136 \n",
      "==> Location -> (84, 72)\n",
      "==> Scale -> 1 Confidence Score 2.4719849198816117 \n",
      "==> Location -> (96, 72)\n",
      "==> Scale -> 1 Confidence Score 1.5588546878204903 \n",
      "==> Location -> (72, 84)\n",
      "==> Scale -> 1 Confidence Score 1.8626375295207305 \n",
      "==> Location -> (0, 108)\n",
      "==> Scale -> 1 Confidence Score 1.686934381888937 \n",
      "==> Location -> (0, 120)\n",
      "==> Scale -> 1 Confidence Score 1.5452900682287287 \n",
      "==> Location -> (108, 132)\n",
      "==> Scale -> 1 Confidence Score 1.5075634300624239 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruisongzhou/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Location -> (60, 36)\n",
      "==> Scale -> 2 Confidence Score 1.6863303980801498 \n",
      "==> Location -> (72, 36)\n",
      "==> Scale -> 2 Confidence Score 1.9100023291446229 \n",
      "==> Location -> (48, 48)\n",
      "==> Scale -> 2 Confidence Score 2.9871258000500855 \n",
      "==> Location -> (60, 48)\n",
      "==> Scale -> 2 Confidence Score 1.8759455670867788 \n",
      "==> Location -> (72, 48)\n",
      "==> Scale -> 2 Confidence Score 1.6005487334127844 \n",
      "==> Location -> (48, 60)\n",
      "==> Scale -> 2 Confidence Score 1.8544600561165276 \n",
      "==> Location -> (72, 60)\n",
      "==> Scale -> 2 Confidence Score 2.042494845763491 \n",
      "==> Location -> (0, 84)\n",
      "==> Scale -> 2 Confidence Score 2.4095350470199772 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruisongzhou/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Location -> (36, 12)\n",
      "==> Scale -> 3 Confidence Score 2.0932313219307215 \n",
      "==> Location -> (60, 12)\n",
      "==> Scale -> 3 Confidence Score 1.5112295897236032 \n",
      "==> Location -> (48, 24)\n",
      "==> Scale -> 3 Confidence Score 2.160921708381471 \n",
      "==> Location -> (60, 24)\n",
      "==> Scale -> 3 Confidence Score 2.5796756195079578 \n",
      "==> Location -> (48, 36)\n",
      "==> Scale -> 3 Confidence Score 1.9640982803935054 \n",
      "==> Location -> (60, 36)\n",
      "==> Scale -> 3 Confidence Score 3.20974731527304 \n",
      "==> Location -> (36, 48)\n",
      "==> Scale -> 3 Confidence Score 1.743368614293791 \n",
      "==> Location -> (60, 48)\n",
      "==> Scale -> 3 Confidence Score 3.1003366598224655 \n",
      "==> Location -> (72, 48)\n",
      "==> Scale -> 3 Confidence Score 2.7448019348287342 \n",
      "==> Location -> (84, 48)\n",
      "==> Scale -> 3 Confidence Score 1.6203050235485585 \n",
      "==> Location -> (60, 60)\n",
      "==> Scale -> 3 Confidence Score 2.013518402199912 \n",
      "==> Location -> (72, 60)\n",
      "==> Scale -> 3 Confidence Score 2.44203324496994 \n",
      "==> Location -> (72, 72)\n",
      "==> Scale -> 3 Confidence Score 2.1765145066035583 \n",
      "==> Location -> (72, 84)\n",
      "==> Scale -> 3 Confidence Score 2.553110386503482 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruisongzhou/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Location -> (48, 0)\n",
      "==> Scale -> 4 Confidence Score 1.9448476738543883 \n",
      "==> Location -> (48, 12)\n",
      "==> Scale -> 4 Confidence Score 2.1487738873718225 \n",
      "==> Location -> (48, 36)\n",
      "==> Scale -> 4 Confidence Score 1.729702610011605 \n",
      "==> Location -> (0, 60)\n",
      "==> Scale -> 4 Confidence Score 1.833559125939933 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruisongzhou/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Location -> (24, 12)\n",
      "==> Scale -> 5 Confidence Score 2.9519999738608984 \n",
      "==> Location -> (36, 12)\n",
      "==> Scale -> 5 Confidence Score 2.5194972647088942 \n",
      "==> Location -> (24, 24)\n",
      "==> Scale -> 5 Confidence Score 1.591569605417822 \n",
      "==> Location -> (24, 36)\n",
      "==> Scale -> 5 Confidence Score 2.4525404027838302 \n",
      "==> Location -> (24, 0)\n",
      "==> Scale -> 6 Confidence Score 1.8569727383608148 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruisongzhou/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/home/ruisongzhou/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/home/ruisongzhou/anaconda3/lib/python3.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Config' object has no attribute 'DIR_PATHS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fe3d3d17ae66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDIR_PATHS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PRED_SAVE_PH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-fe3d3d17ae66>\u001b[0m in \u001b[0;36mtest_classifier\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m#保存结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDIR_PATHS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PRED_SAVE_PH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDIR_PATHS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PRED_SAVE_PH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Config' object has no attribute 'DIR_PATHS'"
     ]
    }
   ],
   "source": [
    "## resize\n",
    "def resize_by_short(img, short_len=256):\n",
    "    print(img.shape)\n",
    "    (x, y) = img.shape\n",
    "    if x > y:\n",
    "        y_s = short_len\n",
    "        x_s = int(x * y_s / y)\n",
    "        img = cv2.resize(img, (x_s, y_s))\n",
    "    else:\n",
    "        x_s = short_len\n",
    "        y_s = int(y * x_s / x)\n",
    "        img = cv2.resize(img, (x_s, y_s))\n",
    "    return img\n",
    "\n",
    "def sliding_window(image, window_size, step_size):\n",
    "    for y in range(0, image.shape[0], step_size[1]):  # 图片的函数为image.shape[0]\n",
    "        for x in range(0, image.shape[1], step_size[0]): # 图片的列数为image.shape[1]\n",
    "            yield (x, y, image[y:y+window_size[1], x:x+window_size[0]])\n",
    "\n",
    "## 测试分类器\n",
    "def test_classifier(config=config):\n",
    "    for im_path in [os.path.join(config.DirPath[\"TEST_DIR_PATH\"], i) for i in os.listdir(config.DirPath[\"TEST_DIR_PATH\"])]:\n",
    "        #img = Image.open(im_path).convert('L')\n",
    "        img = cv2.imread(im_path, 0)\n",
    "        img = np.array(resize_by_short(img))\n",
    "        #return img\n",
    "        # clf\n",
    "        detections = []\n",
    "        scale = 0\n",
    "        \n",
    "        print(\"Processing image %s, shape %s\" % (im_path, str(img.shape)))\n",
    "        ## 图像金字塔\n",
    "        for img_scale in pyramid_gaussian(img, downscale=1.2):\n",
    "            img_scale = (img_scale*255).astype(np.uint8)\n",
    "#             plt.imshow(img_scale)\n",
    "            \n",
    "            cd = []\n",
    "#             print(\"Img_scale shape %s\" % (str(img_scale.shape)))\n",
    "            #plt.imshow(img_scale)\n",
    "            if img_scale.shape[0] < 64 or img_scale.shape[1] < 64:\n",
    "                break\n",
    "            for (x, y, img_window) in sliding_window(img_scale, [64,64], [12,12]):\n",
    "                #print(\"Img_window shape : %s\" % (str(img_window.shape)))\n",
    "                if img_window.shape[0] != 64 or img_window.shape[1] != 64:\n",
    "                    continue\n",
    "                #plt.imshow(img_window)\n",
    "                pred = Classifier(img_window)\n",
    "                score = Classifier(img_window, True)\n",
    "                if pred:  # 如果预测出来有目标\n",
    "                    print(\"==> Location -> ({}, {})\".format(x, y))\n",
    "                    print(\"==> Scale -> {} Confidence Score {} \".format(scale, score))\n",
    "                    detections.append((x, y, score, \n",
    "                                       int(64 * (1.2**scale)), \n",
    "                                       int(64 * (1.2**scale))))\n",
    "                    cd.append(detections[-1])\n",
    "                    \n",
    "                clone = img_scale.copy()\n",
    "                for x1, y1, _, _, _ in cd:\n",
    "                    cv2.rectangle(clone, (x1, y1), (x1 + 64, y1 + 64), (0, 0, 0), thickness=2)\n",
    "                cv2.rectangle(clone, (x, y), (x + 64, y + 64), (255,255,255), thickness=2)\n",
    "                cv2.imshow(\"Sliding Window in Progress\", clone)\n",
    "                cv2.waitKey(30)\n",
    "            scale += 1\n",
    "        #Display the results before permorming NMS\n",
    "        clone = img.copy()\n",
    "        \n",
    "        for (x_tl, y_tl, _, w, h) in detections:\n",
    "            cv2.rectangle(img, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "\n",
    "        detections_fin = nms(detections, 0.3) #perform Non Maxima Suppression\n",
    "        \n",
    "         # Display the results after performing NMS\n",
    "        for (x_tl, y_tl, _, w, h) in detections_fin:\n",
    "            # Draw the detections\n",
    "            cv2.rectangle(clone, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "        \n",
    "        #cv2.imshow(\"Final Detections after applying NMS\", clone)\n",
    "        \n",
    "        #保存结果\n",
    "        print(os.path.join(config.DirPath['PRED_SAVE_PH'], os.path.split(im_path)[1]))\n",
    "        cv2.imwrite(os.path.join(config.DirPath['PRED_SAVE_PH'], os.path.split(im_path)[1]), clone)\n",
    "        \n",
    "test_classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((temp*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./source/test_images/pos_test_3.jpg\", 0)\n",
    "Classifier(img, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img_scale in pyramid_gaussian(img, downscale=1.2):\n",
    "#     plt.imshow(img_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去除文件名中的空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"./source/images/neg_new/\"\n",
    "for file in os.listdir(dirpath):\n",
    "    if \".mp4\" in file:\n",
    "        new_name = file.replace(\".mp4\", \"\")\n",
    "        os.rename(os.path.join(dirpath, file), os.path.join(dirpath, new_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB特征点检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"./source/images/pos/positiveSimples_VID_20181120_204145.mp4_10.jpg\"\n",
    "#path2 = \"./source/images/neg_new/negativeSimples_VID_20181120_204145.mp4_1.jpg\"\n",
    "#path2 = \"./source/test_images/test_6.jpg\"\n",
    "\n",
    "img1 = cv2.imread(path, 0)\n",
    "# img2 = cv2.imread(path2, 0)\n",
    "\n",
    "orb = cv2.ORB_create(nfeatures=200,\n",
    "                     scaleFactor=1.2,\n",
    "                     nlevels=8,\n",
    "                     edgeThreshold=2,\n",
    "                     WTA_K=2,\n",
    "                     scoreType=cv2.ORB_HARRIS_SCORE,\n",
    "                     patchSize=10)\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "# kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "# bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "# matches = bf.match(des1, des2)\n",
    "\n",
    "img3 = cv2.drawKeypoints(img1, kp1, None, 255, 0)\n",
    "# img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:50], None)\n",
    "plt.imshow(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取图片和保存图片路径\n",
    "IMG_DIR_PATH = \"./source/images/pos\"\n",
    "#ORB_IMG_SAVE_PATH = \"./source/orb_feature/neg_new\"\n",
    "\n",
    "## 读取图片\n",
    "ImgNames = os.listdir(IMG_DIR_PATH)\n",
    "start_time = time.time()\n",
    "for name in tqdm.tqdm(ImgNames):\n",
    "    path = os.path.join(IMG_DIR_PATH, name)\n",
    "    img = cv2.imread(path,0)\n",
    "    ## 初始化检测器\n",
    "    orb = cv2.ORB_create(nfeatures=50,\n",
    "                         edgeThreshold=5)\n",
    "    kp, des = orb.detectAndCompute(img, None)\n",
    "\n",
    "    ## 画出关键点的位置\n",
    "    img2 = cv2.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n",
    "    cv2.imwrite(os.path.join(ORB_IMG_SAVE_PATH, name), img2)\n",
    "end_time = time.time()\n",
    "print(\"==> Process {} second.\" % end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"./source/images/neg_new/negativeSimples__196.jpg\",0)\n",
    "img = cv2.imread(\"./source/images/pos/positiveSimples_VID_20181120_204145.mp4_101.jpg\",0)\n",
    "dst = cv2.cornerHarris(img,2,3,0.04)\n",
    "\n",
    "dst = cv2.dilate(dst, None)\n",
    "img[dst>0.01*dst.max()]=255\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
