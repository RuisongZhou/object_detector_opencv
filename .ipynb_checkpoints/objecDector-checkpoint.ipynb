{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import config\n",
    "import feature_extraction \n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import haar_like_feature\n",
    "from skimage.feature import local_binary_pattern as lbp\n",
    "from skimage.io import imread\n",
    "from skimage.transform import pyramid_gaussian, integral_image\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(args=object):\n",
    "    fds = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"==> Loading the positive features\")\n",
    "    for feat_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"POS_FEAT_PH\"], \"*.feat\"))):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd.reshape(-1))\n",
    "        labels.append(1)\n",
    "\n",
    "    print(\"==> Load the negative features\")\n",
    "    for feat_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"NEG_FEAT_PH\"], \"*.feat\"))):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd.reshape(-1))\n",
    "        labels.append(0)\n",
    "\n",
    "    if args.CLF_TYPE is \"LIN_SVM\":\n",
    "        clf = LinearSVC()\n",
    "        print(\"==> Training a Linear SVM Classifier\")\n",
    "        clf.fit(fds, labels)\n",
    "        joblib.dump(clf, args.MODEL_PH)\n",
    "        print(\"==> Classifier saved to {}\".format(args.MODEL_PH))\n",
    "    elif args.CLF_TYPE is \"MLP\":\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(16, 32, 64), random_state=1)\n",
    "        print(\"==> Training a Multi Layer Classifier\")\n",
    "        clf.fit(fds, labels)\n",
    "        joblib.dump(clf, args.MODEL_PH)\n",
    "        print(\"==> Classifier saved to {}\".format(args.MODEL_PH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Non-Maxima Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_area(detection_1, detection_2):\n",
    "    \"\"\"\n",
    "        Function to calculate overlapping area'si\n",
    "        `detection_1` and `detection_2` are 2 detections whose area\n",
    "        of overlap needs to be found out.\n",
    "        Each detection is list in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        The function returns a value between 0 and 1,\n",
    "        which represents the area of overlap.\n",
    "        0 is no overlap and 1 is complete overlap.\n",
    "        Area calculated from ->\n",
    "        http://math.stackexchange.com/questions/99565/simplest-way-to-calculate-the-intersect-area-of-two-rectangles\n",
    "    \"\"\"\n",
    "    # Calculate the x-y co-ordinates of the rectangles\n",
    "    x1_tl = detection_1[0]\n",
    "    x2_tl = detection_2[0]\n",
    "    x1_br = detection_1[0] + detection_1[3]\n",
    "    x2_br = detection_2[0] + detection_2[3]\n",
    "    y1_tl = detection_1[1]\n",
    "    y2_tl = detection_2[1]\n",
    "    y1_br = detection_1[1] + detection_1[4]\n",
    "    y2_br = detection_2[1] + detection_2[4]\n",
    "    # Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br) - max(x1_tl, x2_tl))\n",
    "    y_overlap = max(0, min(y1_br, y2_br) - max(y1_tl, y2_tl))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = detection_1[3] * detection_2[4]\n",
    "    area_2 = detection_2[3] * detection_2[4]\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    return overlap_area / float(total_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(detections, threshold=.5):\n",
    "    \"\"\"\n",
    "        This function performs Non-Maxima Suppression.\n",
    "        `detections` consists of a list of detections.\n",
    "        Each detection is in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        If the area of overlap is greater than the `threshold`,\n",
    "        the area with the lower confidence score is removed.\n",
    "        The output is a list of detections.\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    # Sort the detections based on confidence score\n",
    "    detections = sorted(detections, key=lambda detections: detections[2],\n",
    "                        reverse=True)\n",
    "    new_detections = [] # Unique detections will be appended to this list\n",
    "    new_detections.append(detections[0]) # Append the first detection\n",
    "    del detections[0] # Remove the detection from the original list\n",
    "    \"\"\"\n",
    "        For each detection, calculate the overlapping area\n",
    "        and if area of overlap is less than the threshold set\n",
    "        for the detections in `new_detections`, append the \n",
    "        detection to `new_detections`.\n",
    "        In either case, remove the detection from `detections` list.\n",
    "    \"\"\"\n",
    "    for index, detection in enumerate(detections):\n",
    "        for new_detection in new_detections:\n",
    "            if overlapping_area(detection, new_detection) > threshold:\n",
    "                del detections[index]\n",
    "                break\n",
    "        else:\n",
    "            new_detections.append(detection)\n",
    "            del detections[index]\n",
    "    return new_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_by_short(img, short_len=256):\n",
    "    print(img.size)\n",
    "    (x, y) = img.size\n",
    "    if x > y:\n",
    "        y_s = short_len\n",
    "        x_s = int(x * y_s / y)\n",
    "        img = img.resize((x_s, y_s))\n",
    "    else:\n",
    "        x_s = short_len\n",
    "        y_s = int(y * x_s / x)\n",
    "        img = img.resize((x_s, y_s))\n",
    "    return img\n",
    "\n",
    "\n",
    "def sliding_window(image, window_size, step_size):\n",
    "    \"\"\"\n",
    "        This function returns a patch of the input image `image` of size equal\n",
    "        to `window_size`. The first image returned top-left co-ordinates (0, 0)\n",
    "        and are increment in both x and y directions by the `step_size` supplied.\n",
    "        So, the input parameters are -\n",
    "        * `image` - Input Image\n",
    "        * `window_size` - Size of Sliding Window\n",
    "        * `step_size` - Incremented Size of Window\n",
    "\n",
    "        The function returns a tuple -\n",
    "        (x, y, im_window)\n",
    "        where\n",
    "        * x is the top-left x co-ordinate\n",
    "        * y is the top-left y co-ordinate\n",
    "        * im_window is the sliding window image\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0], step_size[1]):\n",
    "        for x in range(0, image.shape[1], step_size[0]):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "\n",
    "def test_classifier(args=object):\n",
    "    for im_path in [os.path.join(args.DIR_PATHS[\"TEST_IMG_DIR_PH\"], i) for i in os.listdir(args.DIR_PATHS[\"TEST_IMG_DIR_PH\"]) if not i.startswith('.')]:\n",
    "        # Read the Image\n",
    "        im = Image.open(im_path).convert('L')\n",
    "        im = np.array(resize_by_short(im))\n",
    "\n",
    "        clf = joblib.load(args.MODEL_PH) # Load the classifier\n",
    "        detections = [] # List to store the detections\n",
    "        scale = 0 # The current scale of the image\n",
    "\n",
    "        # Downscale the image and iterate\n",
    "        for im_scaled in pyramid_gaussian(im, downscale=args.DOWNSCALE):\n",
    "            cd = [] # This list contains detections at the current scale\n",
    "            # If the width or height of the scaled image is less than\n",
    "            # the width or height of the window, then end the iterations.\n",
    "            if im_scaled.shape[0] < args.MIN_WDW_SIZE[1] or im_scaled.shape[1] < args.MIN_WDW_SIZE[0]:\n",
    "                break\n",
    "            for (x, y, im_window) in sliding_window(im_scaled, args.MIN_WDW_SIZE, args.STEP_SIZE):\n",
    "                if im_window.shape[0] != args.MIN_WDW_SIZE[1] or im_window.shape[1] != args.MIN_WDW_SIZE[0]:\n",
    "                    continue\n",
    "                # Calculate the HOG features\n",
    "                fd = feature_extraction.process_image(im_window,args).reshape([1, -1])\n",
    "                pred = clf.predict(fd)\n",
    "                if pred == 1:\n",
    "                    if args.IF_PRINT: print(\"==> Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                    if args.CLF_TYPE is \"LIN_SVM\":\n",
    "                        if args.IF_PRINT: print(\"==> Scale ->  {} Confidence Score {} \\n\".format(scale, clf.decision_function(fd)))\n",
    "                        detections.append((x, y, clf.decision_function(fd),\n",
    "                                           int(args.MIN_WDW_SIZE[0] * (args.DOWNSCALE ** scale)),\n",
    "                                           int(args.MIN_WDW_SIZE[1] * (args.DOWNSCALE ** scale))))\n",
    "                    elif args.CLF_TYPE is \"MLP\":\n",
    "                        if args.IF_PRINT: print(\"==> Scale ->  {} Confidence Score {} \\n\".format(scale, clf.predict_proba(fd)[0][1]))#clf.decision_function(fd)))\n",
    "                        detections.append((x, y, clf.predict_proba(fd)[0][1],\n",
    "                                           int(args.MIN_WDW_SIZE[0] * (args.DOWNSCALE ** scale)),\n",
    "                                           int(args.MIN_WDW_SIZE[1] * (args.DOWNSCALE ** scale))))\n",
    "                    cd.append(detections[-1])\n",
    "\n",
    "                # If visualize is set to true, display the working of the sliding window\n",
    "                if args.VISUALIZE:\n",
    "                    clone = im_scaled.copy()\n",
    "                    for x1, y1, _, _, _ in cd:\n",
    "                        # Draw the detections at this scale\n",
    "                        cv2.rectangle(clone, (x1, y1), (x1 + im_window.shape[1], y1 +\n",
    "                                                        im_window.shape[0]), (0, 0, 0), thickness=2)\n",
    "                    cv2.rectangle(clone, (x, y), (x + im_window.shape[1], y +\n",
    "                                                  im_window.shape[0]), (255, 255, 255), thickness=2)\n",
    "                    cv2.imshow(\"Sliding Window in Progress\", clone)\n",
    "                    cv2.waitKey(30)\n",
    "\n",
    "            # Move the the next scale\n",
    "            scale += 1\n",
    "\n",
    "        # Display the results before performing NMS\n",
    "        clone = im.copy()\n",
    "\n",
    "        # Draw the detections\n",
    "        for (x_tl, y_tl, _, w, h) in detections:\n",
    "            cv2.rectangle(im, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "\n",
    "        detections_fin = nms(detections, args.THRESHOLD) # Perform Non Maxima Suppression\n",
    "\n",
    "        # Display the results after performing NMS\n",
    "        for (x_tl, y_tl, _, w, h) in detections_fin:\n",
    "            # Draw the detections\n",
    "            cv2.rectangle(clone, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "            \n",
    "        if args.VISUALIZE:\n",
    "            cv2.imshow(\"Final Detections after applying NMS\", clone)\n",
    "            \n",
    "        # print(os.path.split(im_path))\n",
    "        print(os.path.join(args.DIR_PATHS['PRED_SAVE_PH'], os.path.split(im_path)[1]))\n",
    "        cv2.imwrite(os.path.join(args.DIR_PATHS['PRED_SAVE_PH'], os.path.split(im_path)[1]), clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = config.Config()\n",
    "def train(args = args):\n",
    "    feature_extraction.image_preprocess_size(args)\n",
    "    feature_extraction.extract_features(args)\n",
    "    train_classifier(args)\n",
    "    test_classifier(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         self.MIN_WDW_SIZE = [64, 64]\n",
    "#         self.STEP_SIZE = [12, 12]\n",
    "#         self.ORIENTATIONS = 9\n",
    "#         self.PIXELS_PER_CELL = [3, 3]\n",
    "#         self.CELLS_PER_BLOCK = [3, 3]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def grid_search():\n",
    "    for step_size in range(8,36,4):\n",
    "        for pixels_per_cell in range(3,10,1):\n",
    "            for cells_per_block in range(3, 10, 1):\n",
    "                args = config.Config()\n",
    "                args.STEP_SIZE = [step_size, step_size]\n",
    "                args.CELLS_PER_BLOCK = [cells_per_block, cells_per_block]\n",
    "                args.PIXELS_PER_CELL = [pixels_per_cell, pixels_per_cell]\n",
    "                args.PROJECT_ID = args.PROJECT_ID + \"_SS_\" + str(step_size) +\\\n",
    "                        \"_CPB_\" + str(cells_per_block) + \"_PPC_\" + str(pixels_per_cell)\n",
    "                args.update_names()\n",
    "                print(args.PROJECT_ID, args.DIR_PATHS)\n",
    "                args.mk_new_dirs()\n",
    "                feature_extraction.extract_features(args=args)\n",
    "                train_classifier(args=args)\n",
    "                test_classifier(args=args)\n",
    "                if not args.KEEP_FEAT:\n",
    "                    shutil.rmtree(args.DIR_PATHS['NEG_FEAT_PH'])\n",
    "                    shutil.rmtree(args.DIR_PATHS['POS_FEAT_PH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_extraction.image_preprocess_size(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2036 [00:00<00:20, 99.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2036/2036 [00:12<00:00, 163.71it/s]\n",
      "  1%|          | 16/2000 [00:00<00:12, 159.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:11<00:00, 171.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM/neg\n",
      "==> Completed calculating features from training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#feature_extraction.extract_features(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:00<00:00, 3701.58it/s]\n",
      " 21%|██        | 418/2000 [00:00<00:00, 4179.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 4221.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM/svm.model\n"
     ]
    }
   ],
   "source": [
    "#train_classifier(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_8.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_4.jpg\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_2.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/pos_test_0.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_6.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/pos_test_2.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_7.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_5.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/pos_test_3.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/pos_test_1.jpg\n",
      "(1280, 960)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM/test_0.JPG\n"
     ]
    }
   ],
   "source": [
    "#test_classifier(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2036 [00:00<01:16, 26.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2036/2036 [00:16<00:00, 125.09it/s]\n",
      "  1%|          | 16/2000 [00:00<00:12, 159.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:15<00:00, 125.67it/s]\n",
      "100%|██████████| 311/311 [00:00<00:00, 4964.81it/s]\n",
      " 24%|██▍       | 478/2000 [00:00<00:00, 4778.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 4458.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_8.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_4.jpg\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_2.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos_test_0.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_6.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos_test_2.jpg\n",
      "(2320, 2316)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_7.jpg\n",
      "(321, 246)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_5.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos_test_3.jpg\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_1.jpg\n",
      "(64, 64)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/pos_test_1.jpg\n",
      "(1280, 960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2036 [00:00<00:13, 154.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_3_PPC_3/test_0.JPG\n",
      "New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3 {'POS_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos', 'NEG_FEAT_PH': './source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/neg', 'MODEL_DIR_PH': './source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3', 'PRED_SAVE_PH': './source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3', 'POS_IMG_PH': './source/images/pos', 'NEG_IMG_PH': './source/images/neg', 'TEST_IMG_DIR_PH': './source/test_images'}\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos created\n",
      "==> Directory Tree ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/neg created\n",
      "==> Directory Tree ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3 created\n",
      "==> Directory Tree ./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3 created\n",
      "==> Calculating the descriptors for the positive samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2036/2036 [00:12<00:00, 163.45it/s]\n",
      "  1%|          | 17/2000 [00:00<00:12, 162.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Positive features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/pos\n",
      "==> Calculating the descriptors for the negative samples and saving them\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:13<00:00, 147.18it/s]\n",
      "100%|██████████| 311/311 [00:00<00:00, 5131.50it/s]\n",
      " 25%|██▍       | 495/2000 [00:00<00:00, 4943.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Negative features saved in ./source/features/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/neg\n",
      "==> Completed calculating features from training images\n",
      "==> Loading the positive features\n",
      "==> Load the negative features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 4355.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training a Linear SVM Classifier\n",
      "==> Classifier saved to ./source/models/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/svm.model\n",
      "(2320, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_9.JPG\n",
      "(1920, 1920)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_8.JPG\n",
      "(3088, 2320)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_4.jpg\n",
      "(2576, 1932)\n",
      "./source/predictions/New_Vedio_New_NegHOG_LIN_SVM_SS_8_CPB_4_PPC_3/test_3.JPG\n",
      "(2320, 2320)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7ea50c2bdd1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-6478f9a374c4>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKEEP_FEAT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDIR_PATHS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NEG_FEAT_PH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-f8685eecb7e8>\u001b[0m in \u001b[0;36mtest_classifier\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m# Calculate the HOG features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_window\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/card_matching/object_detector_opencv/feature_extraction.py\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(image, args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDES_TYPE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"HOG\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIXELS_PER_CELL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDES_TYPE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"LBP\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlbp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBP_POINTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBP_RADIUS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skimage/feature/_hog.py\u001b[0m in \u001b[0;36mhog\u001b[0;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, visualise, transform_sqrt, feature_vector, multichannel)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morientation_histogram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mnormalized_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0m_hog_normalize_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \"\"\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skimage/feature/_hog.py\u001b[0m in \u001b[0;36m_hog_normalize_block\u001b[0;34m(block, method, eps)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'L2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'L2-Hys'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 1930\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   1931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mpasskwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
