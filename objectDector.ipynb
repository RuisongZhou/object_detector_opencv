{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import config\n",
    "import feature_extraction \n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import haar_like_feature\n",
    "from skimage.feature import local_binary_pattern as lbp\n",
    "from skimage.io import imread\n",
    "from skimage.transform import pyramid_gaussian, integral_image\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(args=object):\n",
    "    fds = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"==> Loading the positive features\")\n",
    "    for feat_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"POS_FEAT_PH\"], \"*.feat\"))):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd.reshape(-1))\n",
    "        labels.append(1)\n",
    "\n",
    "    print(\"==> Load the negative features\")\n",
    "    for feat_path in tqdm(glob.glob(os.path.join(args.DIR_PATHS[\"NEG_FEAT_PH\"], \"*.feat\"))):\n",
    "        fd = joblib.load(feat_path)\n",
    "        fds.append(fd.reshape(-1))\n",
    "        labels.append(0)\n",
    "\n",
    "    if args.CLF_TYPE is \"LIN_SVM\":\n",
    "        clf = LinearSVC()\n",
    "        print(\"==> Training a Linear SVM Classifier\")\n",
    "        clf.fit(fds, labels)\n",
    "        joblib.dump(clf, args.MODEL_PH)\n",
    "        print(\"==> Classifier saved to {}\".format(args.MODEL_PH))\n",
    "    elif args.CLF_TYPE is \"MLP\":\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(16, 32, 64), random_state=1)\n",
    "        print(\"==> Training a Multi Layer Classifier\")\n",
    "        clf.fit(fds, labels)\n",
    "        joblib.dump(clf, args.MODEL_PH)\n",
    "        print(\"==> Classifier saved to {}\".format(args.MODEL_PH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Non-Maxima Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_area(detection_1, detection_2):\n",
    "    \"\"\"\n",
    "        Function to calculate overlapping area'si\n",
    "        `detection_1` and `detection_2` are 2 detections whose area\n",
    "        of overlap needs to be found out.\n",
    "        Each detection is list in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        The function returns a value between 0 and 1,\n",
    "        which represents the area of overlap.\n",
    "        0 is no overlap and 1 is complete overlap.\n",
    "        Area calculated from ->\n",
    "        http://math.stackexchange.com/questions/99565/simplest-way-to-calculate-the-intersect-area-of-two-rectangles\n",
    "    \"\"\"\n",
    "    # Calculate the x-y co-ordinates of the rectangles\n",
    "    x1_tl = detection_1[0]\n",
    "    x2_tl = detection_2[0]\n",
    "    x1_br = detection_1[0] + detection_1[3]\n",
    "    x2_br = detection_2[0] + detection_2[3]\n",
    "    y1_tl = detection_1[1]\n",
    "    y2_tl = detection_2[1]\n",
    "    y1_br = detection_1[1] + detection_1[4]\n",
    "    y2_br = detection_2[1] + detection_2[4]\n",
    "    # Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br) - max(x1_tl, x2_tl))\n",
    "    y_overlap = max(0, min(y1_br, y2_br) - max(y1_tl, y2_tl))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = detection_1[3] * detection_2[4]\n",
    "    area_2 = detection_2[3] * detection_2[4]\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    return overlap_area / float(total_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(detections, threshold=.5):\n",
    "    \"\"\"\n",
    "        This function performs Non-Maxima Suppression.\n",
    "        `detections` consists of a list of detections.\n",
    "        Each detection is in the format ->\n",
    "        [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "        If the area of overlap is greater than the `threshold`,\n",
    "        the area with the lower confidence score is removed.\n",
    "        The output is a list of detections.\n",
    "    \"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    # Sort the detections based on confidence score\n",
    "    detections = sorted(detections, key=lambda detections: detections[2],\n",
    "                        reverse=True)\n",
    "    new_detections = [] # Unique detections will be appended to this list\n",
    "    new_detections.append(detections[0]) # Append the first detection\n",
    "    del detections[0] # Remove the detection from the original list\n",
    "    \"\"\"\n",
    "        For each detection, calculate the overlapping area\n",
    "        and if area of overlap is less than the threshold set\n",
    "        for the detections in `new_detections`, append the \n",
    "        detection to `new_detections`.\n",
    "        In either case, remove the detection from `detections` list.\n",
    "    \"\"\"\n",
    "    for index, detection in enumerate(detections):\n",
    "        for new_detection in new_detections:\n",
    "            if overlapping_area(detection, new_detection) > threshold:\n",
    "                del detections[index]\n",
    "                break\n",
    "        else:\n",
    "            new_detections.append(detection)\n",
    "            del detections[index]\n",
    "    return new_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_by_short(img, short_len=256):\n",
    "    print(img.size)\n",
    "    (x, y) = img.size\n",
    "    if x > y:\n",
    "        y_s = short_len\n",
    "        x_s = int(x * y_s / y)\n",
    "        img = img.resize((x_s, y_s))\n",
    "    else:\n",
    "        x_s = short_len\n",
    "        y_s = int(y * x_s / x)\n",
    "        img = img.resize((x_s, y_s))\n",
    "    return img\n",
    "\n",
    "\n",
    "def sliding_window(image, window_size, step_size):\n",
    "    \"\"\"\n",
    "        This function returns a patch of the input image `image` of size equal\n",
    "        to `window_size`. The first image returned top-left co-ordinates (0, 0)\n",
    "        and are increment in both x and y directions by the `step_size` supplied.\n",
    "        So, the input parameters are -\n",
    "        * `image` - Input Image\n",
    "        * `window_size` - Size of Sliding Window\n",
    "        * `step_size` - Incremented Size of Window\n",
    "\n",
    "        The function returns a tuple -\n",
    "        (x, y, im_window)\n",
    "        where\n",
    "        * x is the top-left x co-ordinate\n",
    "        * y is the top-left y co-ordinate\n",
    "        * im_window is the sliding window image\n",
    "    \"\"\"\n",
    "    for y in range(0, image.shape[0], step_size[1]):\n",
    "        for x in range(0, image.shape[1], step_size[0]):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "\n",
    "def test_classifier(args=object):\n",
    "    for im_path in [os.path.join(args.DIR_PATHS[\"TEST_IMG_DIR_PH\"], i) for i in os.listdir(args.DIR_PATHS[\"TEST_IMG_DIR_PH\"]) if not i.startswith('.')]:\n",
    "        # Read the Image\n",
    "        im = Image.open(im_path).convert('L')\n",
    "        im = np.array(resize_by_short(im))\n",
    "\n",
    "        clf = joblib.load(args.MODEL_PH) # Load the classifier\n",
    "        detections = [] # List to store the detections\n",
    "        scale = 0 # The current scale of the image\n",
    "\n",
    "        # Downscale the image and iterate\n",
    "        for im_scaled in pyramid_gaussian(im, downscale=args.DOWNSCALE):\n",
    "            cd = [] # This list contains detections at the current scale\n",
    "            # If the width or height of the scaled image is less than\n",
    "            # the width or height of the window, then end the iterations.\n",
    "            if im_scaled.shape[0] < args.MIN_WDW_SIZE[1] or im_scaled.shape[1] < args.MIN_WDW_SIZE[0]:\n",
    "                break\n",
    "            for (x, y, im_window) in sliding_window(im_scaled, args.MIN_WDW_SIZE, args.STEP_SIZE):\n",
    "                if im_window.shape[0] != args.MIN_WDW_SIZE[1] or im_window.shape[1] != args.MIN_WDW_SIZE[0]:\n",
    "                    continue\n",
    "                # Calculate the HOG features\n",
    "                fd = feature_extraction.process_image(im_window,args).reshape([1, -1])\n",
    "                pred = clf.predict(fd)\n",
    "                if pred == 1:\n",
    "                    if args.IF_PRINT: print(\"==> Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                    if args.CLF_TYPE is \"LIN_SVM\":\n",
    "                        if args.IF_PRINT: print(\"==> Scale ->  {} Confidence Score {} \\n\".format(scale, clf.decision_function(fd)))\n",
    "                        detections.append((x, y, clf.decision_function(fd),\n",
    "                                           int(args.MIN_WDW_SIZE[0] * (args.DOWNSCALE ** scale)),\n",
    "                                           int(args.MIN_WDW_SIZE[1] * (args.DOWNSCALE ** scale))))\n",
    "                    elif args.CLF_TYPE is \"MLP\":\n",
    "                        if args.IF_PRINT: print(\"==> Scale ->  {} Confidence Score {} \\n\".format(scale, clf.predict_proba(fd)[0][1]))#clf.decision_function(fd)))\n",
    "                        detections.append((x, y, clf.predict_proba(fd)[0][1],\n",
    "                                           int(args.MIN_WDW_SIZE[0] * (args.DOWNSCALE ** scale)),\n",
    "                                           int(args.MIN_WDW_SIZE[1] * (args.DOWNSCALE ** scale))))\n",
    "                    cd.append(detections[-1])\n",
    "\n",
    "                # If visualize is set to true, display the working of the sliding window\n",
    "                if args.VISUALIZE:\n",
    "                    clone = im_scaled.copy()\n",
    "                    for x1, y1, _, _, _ in cd:\n",
    "                        # Draw the detections at this scale\n",
    "                        cv2.rectangle(clone, (x1, y1), (x1 + im_window.shape[1], y1 +\n",
    "                                                        im_window.shape[0]), (0, 0, 0), thickness=2)\n",
    "                    cv2.rectangle(clone, (x, y), (x + im_window.shape[1], y +\n",
    "                                                  im_window.shape[0]), (255, 255, 255), thickness=2)\n",
    "                    cv2.imshow(\"Sliding Window in Progress\", clone)\n",
    "                    cv2.waitKey(30)\n",
    "\n",
    "            # Move the the next scale\n",
    "            scale += 1\n",
    "\n",
    "        # Display the results before performing NMS\n",
    "        clone = im.copy()\n",
    "\n",
    "        # Draw the detections\n",
    "        for (x_tl, y_tl, _, w, h) in detections:\n",
    "            cv2.rectangle(im, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "\n",
    "        detections_fin = nms(detections, args.THRESHOLD) # Perform Non Maxima Suppression\n",
    "\n",
    "        # Display the results after performing NMS\n",
    "        for (x_tl, y_tl, _, w, h) in detections_fin:\n",
    "            # Draw the detections\n",
    "            cv2.rectangle(clone, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 0), thickness=2)\n",
    "            \n",
    "        if args.VISUALIZE:\n",
    "            cv2.imshow(\"Final Detections after applying NMS\", clone)\n",
    "            \n",
    "        # print(os.path.split(im_path))\n",
    "        print(os.path.join(args.DIR_PATHS['PRED_SAVE_PH'], os.path.split(im_path)[1]))\n",
    "        cv2.imwrite(os.path.join(args.DIR_PATHS['PRED_SAVE_PH'], os.path.split(im_path)[1]), clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = config.Config()\n",
    "def train(args = args):\n",
    "    feature_extraction.image_preprocess_size(args)\n",
    "    feature_extraction.extract_features(args)\n",
    "    train_classifier(args)\n",
    "    test_classifier(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         self.MIN_WDW_SIZE = [64, 64]\n",
    "#         self.STEP_SIZE = [12, 12]\n",
    "#         self.ORIENTATIONS = 9\n",
    "#         self.PIXELS_PER_CELL = [3, 3]\n",
    "#         self.CELLS_PER_BLOCK = [3, 3]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def grid_search():\n",
    "    for step_size in range(8,36,4):\n",
    "        for pixels_per_cell in range(3,10,1):\n",
    "            for cells_per_block in range(3, 10, 1):\n",
    "                args = config.Config()\n",
    "                args.STEP_SIZE = [step_size, step_size]\n",
    "                args.CELLS_PER_BLOCK = [cells_per_block, cells_per_block]\n",
    "                args.PIXELS_PER_CELL = [pixels_per_cell, pixels_per_cell]\n",
    "                args.PROJECT_ID = args.PROJECT_ID + \"_SS_\" + str(step_size) +\\\n",
    "                        \"_CPB_\" + str(cells_per_block) + \"_PPC_\" + str(pixels_per_cell)\n",
    "                args.update_names()\n",
    "                print(args.PROJECT_ID, args.DIR_PATHS)\n",
    "                args.mk_new_dirs()\n",
    "                feature_extraction.extract_features(args=args)\n",
    "                train_classifier(args=args)\n",
    "                test_classifier(args=args)\n",
    "                if not args.KEEP_FEAT:\n",
    "                    shutil.rmtree(args.DIR_PATHS['NEG_FEAT_PH'])\n",
    "                    shutil.rmtree(args.DIR_PATHS['POS_FEAT_PH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_extraction.image_preprocess_size(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_extraction.extract_features(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_classifier(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_classifier(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
